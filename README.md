# MinimalRAG - Lightweight NotebookLM Clone

A minimal Retrieval-Augmented Generation (RAG) chatbot that lets you upload documents and ask questions about them.

## Features

- ğŸ“„ Document upload (PDF, TXT, DOCX)
- ğŸ” Semantic search using embeddings
- ğŸ’¬ Chat interface with context-aware responses
- ğŸ“ Source attribution for answers
- ğŸ’¾ Local vector storage with FAISS

## Setup

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Set up your API key:
```bash
export GOOGLE_API_KEY="your-gemini-api-key-here"
```

3. Run the app:
```bash
streamlit run app.py
```

## Tech Stack

- **Frontend**: Streamlit
- **Vector DB**: FAISS
- **Embeddings**: Sentence Transformers (all-MiniLM-L6-v2)
- **LLM**: Google Gemini Pro
- **Document Processing**: LangChain

## Usage

1. Upload one or more documents using the sidebar
2. Wait for processing to complete
3. Start asking questions in the chat interface
4. View answers with source references

## Project Structure

```
minimal-rag/
â”œâ”€â”€ app.py                 # Main Streamlit application
â”œâ”€â”€ document_processor.py  # Document ingestion and chunking
â”œâ”€â”€ vector_store.py       # FAISS vector store management
â”œâ”€â”€ rag_chain.py          # RAG logic and LLM integration
â”œâ”€â”€ requirements.txt      # Dependencies
â””â”€â”€ README.md            # This file
```